{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4afa6a21",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to provide a unified interface to our code for doing data generation.\n",
    "\n",
    "We plan to do experiment with the following things:\n",
    "\n",
    "**Circuit**\n",
    "\n",
    "We will use circuits 1, 6, 9, and 14, as they cover a variety of circuit expressibilities and entangling capabilities.\n",
    "\n",
    "| | High Ent | Low Ent |\n",
    "| --- | --- | --- |\n",
    "| High Exp|6 | 14 |\n",
    "|Low Exp| 9 | 1 |\n",
    "\n",
    "**Data sets**\n",
    "\n",
    "We will use 4 data sets:\n",
    "\n",
    "* Data set 0 (2 blobs, separable)\n",
    "* Data set 1 (2 blobs, inseparable)\n",
    "* Data set 2a (4 blobs, separable)\n",
    "* Data set 3c (4 blobs) <-- Saesun's choice\n",
    "\n",
    "**Learning rates**\n",
    "\n",
    "We will investigate several learning rates.\n",
    "\n",
    "----------------\n",
    "\n",
    "The code below will help us set up our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "769a087c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kim8104\\Anaconda3\\envs\\my-torch\\lib\\site-packages\\qiskit\\__init__.py:67: DeprecationWarning: Using Qiskit with Python 3.6 is deprecated as of the 0.17.0 release. Support for running Qiskit with Python 3.6 will be removed in a future release.\n",
      "  \"future release.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# The code below is a hack in case Travis' kernel fails.\n",
    "#import os\n",
    "#os.environ['KMP_DUPLICATE_LIB_OK'] ='True'\n",
    "\n",
    "# Pull in the helper files.\n",
    "%run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaaa32a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the experiment\n",
    "circuitID = 14\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0980fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------dataset 0 is initialized------\n",
      "__Learning Rate ( 0.01 ) is intialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kim8104\\Anaconda3\\envs\\my-torch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__Learning Rate ( 0.01 ) is done\n",
      "__Learning Rate ( 0.04 ) is intialized\n",
      "__Learning Rate ( 0.04 ) is done\n",
      "__Learning Rate ( 0.09 ) is intialized\n",
      "__Learning Rate ( 0.09 ) is done\n",
      "__Learning Rate ( 0.16 ) is intialized\n",
      "__Learning Rate ( 0.16 ) is done\n",
      "__Learning Rate ( 0.25 ) is intialized\n",
      "__Learning Rate ( 0.25 ) is done\n",
      "__Learning Rate ( 0.36 ) is intialized\n",
      "__Learning Rate ( 0.36 ) is done\n",
      "__Learning Rate ( 0.49 ) is intialized\n",
      "__Learning Rate ( 0.49 ) is done\n",
      "__Learning Rate ( 0.64 ) is intialized\n",
      "__Learning Rate ( 0.64 ) is done\n",
      "__Learning Rate ( 0.81 ) is intialized\n",
      "__Learning Rate ( 0.81 ) is done\n",
      "__Learning Rate ( 1.0 ) is intialized\n",
      "__Learning Rate ( 1.0 ) is done\n",
      "__Learning Rate ( 1.21 ) is intialized\n",
      "__Learning Rate ( 1.21 ) is done\n",
      "__Learning Rate ( 1.44 ) is intialized\n",
      "__Learning Rate ( 1.44 ) is done\n",
      "__Learning Rate ( 1.69 ) is intialized\n",
      "__Learning Rate ( 1.69 ) is done\n",
      "__Learning Rate ( 1.96 ) is intialized\n",
      "__Learning Rate ( 1.96 ) is done\n",
      "__Learning Rate ( 2.25 ) is intialized\n",
      "__Learning Rate ( 2.25 ) is done\n",
      "__Learning Rate ( 2.56 ) is intialized\n",
      "__Learning Rate ( 2.56 ) is done\n",
      "__Learning Rate ( 2.89 ) is intialized\n",
      "__Learning Rate ( 2.89 ) is done\n",
      "__Learning Rate ( 3.24 ) is intialized\n",
      "__Learning Rate ( 3.24 ) is done\n",
      "__Learning Rate ( 3.61 ) is intialized\n",
      "__Learning Rate ( 3.61 ) is done\n",
      "__Learning Rate ( 4.0 ) is intialized\n",
      "__Learning Rate ( 4.0 ) is done\n",
      "--------dataset 1a is initialized------\n",
      "__Learning Rate ( 0.01 ) is intialized\n",
      "__Learning Rate ( 0.01 ) is done\n",
      "__Learning Rate ( 0.04 ) is intialized\n",
      "__Learning Rate ( 0.04 ) is done\n",
      "__Learning Rate ( 0.09 ) is intialized\n",
      "__Learning Rate ( 0.09 ) is done\n",
      "__Learning Rate ( 0.16 ) is intialized\n",
      "__Learning Rate ( 0.16 ) is done\n",
      "__Learning Rate ( 0.25 ) is intialized\n",
      "__Learning Rate ( 0.25 ) is done\n",
      "__Learning Rate ( 0.36 ) is intialized\n",
      "__Learning Rate ( 0.36 ) is done\n",
      "__Learning Rate ( 0.49 ) is intialized\n",
      "__Learning Rate ( 0.49 ) is done\n",
      "__Learning Rate ( 0.64 ) is intialized\n",
      "__Learning Rate ( 0.64 ) is done\n",
      "__Learning Rate ( 0.81 ) is intialized\n",
      "__Learning Rate ( 0.81 ) is done\n",
      "__Learning Rate ( 1.0 ) is intialized\n",
      "__Learning Rate ( 1.0 ) is done\n",
      "__Learning Rate ( 1.21 ) is intialized\n",
      "__Learning Rate ( 1.21 ) is done\n",
      "__Learning Rate ( 1.44 ) is intialized\n",
      "__Learning Rate ( 1.44 ) is done\n",
      "__Learning Rate ( 1.69 ) is intialized\n",
      "__Learning Rate ( 1.69 ) is done\n",
      "__Learning Rate ( 1.96 ) is intialized\n",
      "__Learning Rate ( 1.96 ) is done\n",
      "__Learning Rate ( 2.25 ) is intialized\n",
      "__Learning Rate ( 2.25 ) is done\n",
      "__Learning Rate ( 2.56 ) is intialized\n",
      "__Learning Rate ( 2.56 ) is done\n",
      "__Learning Rate ( 2.89 ) is intialized\n",
      "__Learning Rate ( 2.89 ) is done\n",
      "__Learning Rate ( 3.24 ) is intialized\n",
      "__Learning Rate ( 3.24 ) is done\n",
      "__Learning Rate ( 3.61 ) is intialized\n",
      "__Learning Rate ( 3.61 ) is done\n",
      "__Learning Rate ( 4.0 ) is intialized\n",
      "__Learning Rate ( 4.0 ) is done\n",
      "--------dataset 2a is initialized------\n",
      "__Learning Rate ( 0.01 ) is intialized\n",
      "__Learning Rate ( 0.01 ) is done\n",
      "__Learning Rate ( 0.04 ) is intialized\n",
      "__Learning Rate ( 0.04 ) is done\n",
      "__Learning Rate ( 0.09 ) is intialized\n",
      "__Learning Rate ( 0.09 ) is done\n",
      "__Learning Rate ( 0.16 ) is intialized\n",
      "__Learning Rate ( 0.16 ) is done\n",
      "__Learning Rate ( 0.25 ) is intialized\n",
      "__Learning Rate ( 0.25 ) is done\n",
      "__Learning Rate ( 0.36 ) is intialized\n",
      "__Learning Rate ( 0.36 ) is done\n",
      "__Learning Rate ( 0.49 ) is intialized\n",
      "__Learning Rate ( 0.49 ) is done\n",
      "__Learning Rate ( 0.64 ) is intialized\n",
      "__Learning Rate ( 0.64 ) is done\n",
      "__Learning Rate ( 0.81 ) is intialized\n",
      "__Learning Rate ( 0.81 ) is done\n",
      "__Learning Rate ( 1.0 ) is intialized\n",
      "__Learning Rate ( 1.0 ) is done\n",
      "__Learning Rate ( 1.21 ) is intialized\n",
      "__Learning Rate ( 1.21 ) is done\n",
      "__Learning Rate ( 1.44 ) is intialized\n",
      "__Learning Rate ( 1.44 ) is done\n",
      "__Learning Rate ( 1.69 ) is intialized\n",
      "__Learning Rate ( 1.69 ) is done\n",
      "__Learning Rate ( 1.96 ) is intialized\n",
      "__Learning Rate ( 1.96 ) is done\n",
      "__Learning Rate ( 2.25 ) is intialized\n",
      "__Learning Rate ( 2.25 ) is done\n",
      "__Learning Rate ( 2.56 ) is intialized\n",
      "__Learning Rate ( 2.56 ) is done\n",
      "__Learning Rate ( 2.89 ) is intialized\n",
      "__Learning Rate ( 2.89 ) is done\n",
      "__Learning Rate ( 3.24 ) is intialized\n",
      "__Learning Rate ( 3.24 ) is done\n",
      "__Learning Rate ( 3.61 ) is intialized\n",
      "__Learning Rate ( 3.61 ) is done\n",
      "__Learning Rate ( 4.0 ) is intialized\n",
      "__Learning Rate ( 4.0 ) is done\n",
      "--------dataset 3c is initialized------\n",
      "__Learning Rate ( 0.01 ) is intialized\n",
      "__Learning Rate ( 0.01 ) is done\n",
      "__Learning Rate ( 0.04 ) is intialized\n",
      "__Learning Rate ( 0.04 ) is done\n",
      "__Learning Rate ( 0.09 ) is intialized\n",
      "__Learning Rate ( 0.09 ) is done\n",
      "__Learning Rate ( 0.16 ) is intialized\n",
      "__Learning Rate ( 0.16 ) is done\n",
      "__Learning Rate ( 0.25 ) is intialized\n",
      "__Learning Rate ( 0.25 ) is done\n",
      "__Learning Rate ( 0.36 ) is intialized\n",
      "__Learning Rate ( 0.36 ) is done\n",
      "__Learning Rate ( 0.49 ) is intialized\n",
      "__Learning Rate ( 0.49 ) is done\n",
      "__Learning Rate ( 0.64 ) is intialized\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import sys\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "lr_list=[round(((i+1)/10)**2,2) for i in range(20)]\n",
    "ds_list=['0','1a','2a','3c']\n",
    "\n",
    "for dsID in ds_list:\n",
    "# Run the experiment\n",
    "    print('--------dataset',dsID,'is initialized------')\n",
    "    lr_acc=[]\n",
    "    for lr in lr_list:\n",
    "        # Load in the data\n",
    "        data = load_data(dsID)\n",
    "\n",
    "        # Generate the splittings\n",
    "        train_X, train_y, validate_X, validate_y, test_X, test_y = generate_train_validate_test_data(data)\n",
    "\n",
    "        # Make the feature map\n",
    "        feature_map= make_embedding_circuit()\n",
    "\n",
    "        # Make the classifier\n",
    "        ansatz = make_classifer_circuit(circuitID)\n",
    "\n",
    "        # Do the training\n",
    "        model = train_model(feature_map, ansatz, epochs, lr, train_X, train_y)\n",
    "\n",
    "        # Check the validation accuracy.\n",
    "        val_accuracy = check_accuracy(model, validate_X, validate_y)\n",
    "\n",
    "        lr_acc.append([lr,val_accuracy])\n",
    "    np.savetxt(r\"Learning_Rate_Data\\circuit{0}_data{1}.txt\".format(circuitID,dsID),lr_acc,fmt='%.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb500bff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
