{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qiskit-terra': '0.17.1', 'qiskit-aer': '0.8.1', 'qiskit-ignis': '0.6.0', 'qiskit-ibmq-provider': '0.12.2', 'qiskit-aqua': '0.9.1', 'qiskit': '0.25.1', 'qiskit-nature': None, 'qiskit-finance': None, 'qiskit-optimization': None, 'qiskit-machine-learning': None}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import qiskit\n",
    "qiskit.__qiskit_version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, CrossEntropyLoss, MSELoss\n",
    "from torch.optim import LBFGS, SGD,Adam \n",
    "\n",
    "from qiskit  import Aer, QuantumCircuit\n",
    "from qiskit.utils import QuantumInstance\n",
    "from qiskit.opflow import AerPauliExpectation\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_machine_learning.neural_networks import CircuitQNN, TwoLayerQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.nn import (Module, Conv2d, Linear, Dropout2d, NLLLoss,\n",
    "                     MaxPool2d, Flatten, Sequential, ReLU)\n",
    "\n",
    "qi = QuantumInstance(Aer.get_backend('statevector_simulator'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Test 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import pi\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.nn import (Module, Conv2d, Linear, Dropout2d, NLLLoss,\n",
    "                     MaxPool2d, Flatten, Sequential, ReLU)\n",
    "\n",
    "data0Path = r'../../../dataset/data1c.txt'\n",
    "data0Label = r'../../../dataset/data1clabel.txt'\n",
    "dataCoords = np.loadtxt(data0Path)\n",
    "dataLabels = np.loadtxt(data0Label)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data1 = list(zip(dataCoords, 2*dataLabels-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary(x):\n",
    "    return ('0'*(4-len('{:b}'.format(x) ))+'{:b}'.format(x))\n",
    "def firsttwo(x):\n",
    "    return x[:2]\n",
    "parity = lambda x: firsttwo(binary(x)).count('1') % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 206.997x264.88 with 1 Axes>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas.core.common import flatten\n",
    "import torch\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data1), size=100)\n",
    "\n",
    "X= [np.array(list(flatten([data1[j][0],data1[j][0]]))) for j in data_ixs]\n",
    "y = [data1[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "num_inputs=4;\n",
    "\n",
    "feature_map = QuantumCircuit(4, name='Embed')\n",
    "feature_map.rx(Parameter('x[0]'),0)\n",
    "feature_map.rx(Parameter('x[1]'),1)\n",
    "feature_map.rx(Parameter('x[2]'),2)\n",
    "feature_map.rx(Parameter('x[3]'),3)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.ry(pi/4,2)\n",
    "feature_map.ry(pi/4,3)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "feature_map.rz(pi/4,2)\n",
    "feature_map.rz(pi/4,3)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(12):\n",
    "    param_y.append((Parameter('θ'+str(i))))\n",
    "ansatz = QuantumCircuit(4, name='PQC')\n",
    "for i in range(4):\n",
    "    ansatz.rx(param_y[i],i)\n",
    "for i in range(4):\n",
    "    ansatz.rz(param_y[i+4],i)\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "ansatz.draw('mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Optimzizer LBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate is  0.01\n",
      "68.92813110351562\n",
      "68.8905029296875\n",
      "68.66575622558594\n",
      "68.4361572265625\n",
      "68.20259094238281\n",
      "67.96611785888672\n",
      "67.72796630859375\n",
      "67.48957061767578\n",
      "66.13420867919922\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-36368311a6b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;31m# run optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\optim\\lbfgs.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    435\u001b[0m                     \u001b[1;31m# no use to re-evaluate that function here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m                     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m                         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m                     \u001b[0mflat_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gather_flat_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[0mopt_cond\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflat_grad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mtolerance_grad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-36368311a6b0>\u001b[0m in \u001b[0;36mclosure\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m           \u001b[1;31m# forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mf_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_target\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m                              \u001b[1;31m# backward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m                           \u001b[1;31m# print loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parity = lambda x: firsttwo(binary(x)).count('1') % 2\n",
    "\n",
    "learningR=[round(((i+1)/10)**2,2) for i in range(20)]\n",
    "   \n",
    "output_shape=2;\n",
    "\n",
    "model=[];\n",
    "lossLR=[];\n",
    "\n",
    "\n",
    "for l in learningR:\n",
    "    np.random.seed(2)\n",
    "    qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                      interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "    initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "    # set up PyTorch module\n",
    "    model2 = TorchConnector(qnn2, initial_weights)\n",
    "    # define optimizer and loss function\n",
    "    optimizer = LBFGS(model2.parameters(),lr=l,max_iter=10)\n",
    "    f_loss = CrossEntropyLoss()\n",
    "\n",
    "    # start training\n",
    "    model2.train()   # set model to training mode\n",
    "    \n",
    "    print(\"Learning Rate is \", l)\n",
    "    # define objective function\n",
    "    # define objective function\n",
    "    def closure():\n",
    "        optimizer.zero_grad()        # initialize gradient\n",
    "        loss = 0.0                                             # initialize loss    \n",
    "        for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "            output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "            loss += f_loss(output, Tensor([y_target]).long())\n",
    "        loss.backward()                              # backward pass\n",
    "        print(loss.item())                           # print loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "    # run optimizer\n",
    "    optimizer.step(closure)\n",
    "    model.append(model2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln=len(learningR)\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "accLR=[];\n",
    "for lr in range(ln):\n",
    "\n",
    "    ax = fig.add_subplot(ln, 2, 2*lr+1)\n",
    "    y_predict = []\n",
    "    for x in X:\n",
    "        output = model[lr](Tensor(x))\n",
    "        y_predict += [np.argmax(output.detach().numpy())]\n",
    "    acc=sum(y_predict == np.array(y01))/len(np.array(y01))\n",
    "    print('Learning Rate:', learningR[lr],' Accuracy:', acc)\n",
    "    accLR.append(acc)\n",
    "    # plot results\n",
    "    # red == wrongly classified\n",
    "    for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "        if y_target == 1:\n",
    "            ax.plot(x[0], x[1], 'bo')\n",
    "        else:\n",
    "            ax.plot(x[0], x[1], 'go')\n",
    "        if y_target != y_:\n",
    "            ax.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "\n",
    "\n",
    "    ax = fig.add_subplot(ln, 2, 2*lr+2)\n",
    "    for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "        if y_target == 1:\n",
    "            ax.plot(x[0], x[1], 'bo')\n",
    "        else:\n",
    "            ax.plot(x[0], x[1], 'go')\n",
    "\n",
    "    X1 = np.linspace(0, 1, num=10)\n",
    "    Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "    # Contour map\n",
    "    for j in range(len(X1)):\n",
    "        for k in range(len(X1)):\n",
    "            # Fill Z with the labels (numerical values)\n",
    "            # the inner loop goes over the columns of Z,\n",
    "            # which corresponds to sweeping x-values\n",
    "            # Therefore, the role of j,k is flipped in the signature\n",
    "            Z1[j, k] = np.argmax(model[lr](Tensor([X1[k],X1[j],X1[k],X1[j]])).detach().numpy())\n",
    "\n",
    "    ax.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=fig\n",
    "f1.set_size_inches(10, 80)\n",
    "f1.savefig('LBFGS_1c.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(learningR,accLR, label = \"Accuracy\")\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
