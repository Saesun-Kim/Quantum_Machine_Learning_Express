{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4afa6a21",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to provide a unified interface to our code for doing data generation.\n",
    "\n",
    "We plan to do experiment with the following things:\n",
    "\n",
    "**Circuit**\n",
    "\n",
    "We will use circuits 1, 6, 9, and 14, as they cover a variety of circuit expressibilities and entangling capabilities.\n",
    "\n",
    "| | High Ent | Low Ent |\n",
    "| --- | --- | --- |\n",
    "| High Exp|6 | 14 |\n",
    "|Low Exp| 9 | 1 |\n",
    "\n",
    "**Data sets**\n",
    "\n",
    "We will use 4 data sets:\n",
    "\n",
    "* Data set 0 (2 blobs, separable)\n",
    "* Data set 1 (2 blobs, inseparable)\n",
    "* Data set 2a (4 blobs, separable)\n",
    "* Data set 3c (4 blobs) <-- Saesun's choice\n",
    "\n",
    "**Learning rates**\n",
    "\n",
    "We will investigate several learning rates.\n",
    "\n",
    "----------------\n",
    "\n",
    "The code below will help us set up our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "769a087c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kim8104\\Anaconda3\\envs\\my-torch\\lib\\site-packages\\qiskit\\__init__.py:67: DeprecationWarning: Using Qiskit with Python 3.6 is deprecated as of the 0.17.0 release. Support for running Qiskit with Python 3.6 will be removed in a future release.\n",
      "  \"future release.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# The code below is a hack in case Travis' kernel fails.\n",
    "#import os\n",
    "#os.environ['KMP_DUPLICATE_LIB_OK'] ='True'\n",
    "\n",
    "# Pull in the helper files.\n",
    "%run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaaa32a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the experiment\n",
    "circuitID = 9\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd0980fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------dataset 0 is initialized------\n",
      "__Learning Rate ( 0.01 ) is intialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kim8104\\Anaconda3\\envs\\my-torch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__Learning Rate ( 0.01 ) is done\n",
      "__Learning Rate ( 0.04 ) is intialized\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a4d977283965>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# Do the training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mansatz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# Check the validation accuracy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\Quantum_Machine_Learning_Express\\Machine Learning PQC\\Four_Qubit_pytorch\\experiments.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(feature_map, ansatz, epochs, learning_rate, train_X, train_y, qi)\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mf_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m                              \u001b[1;31m# backward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;31m# run optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\my-torch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\my-torch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\my-torch\\lib\\site-packages\\torch\\autograd\\function.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;31m# _forward_cls is defined by derived class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_cls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\my-torch\\lib\\site-packages\\qiskit_machine_learning\\connectors\\torch_connector.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(ctx, grad_output)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[1;31m# evaluate QNN gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m             \u001b[0minput_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneural_network\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0minput_grad\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_grad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\my-torch\\lib\\site-packages\\qiskit_machine_learning\\neural_networks\\neural_network.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, input_data, weights)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0minput_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0mweights_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0minput_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0minput_grad_reshaped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_grad_reshaped\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\my-torch\\lib\\site-packages\\qiskit_machine_learning\\neural_networks\\sampling_neural_network.py\u001b[0m in \u001b[0;36m_backward\u001b[1;34m(self, input_data, weights)\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_probability_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     def sample(self, input_data: Union[List[float], np.ndarray, float],\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\my-torch\\lib\\site-packages\\qiskit_machine_learning\\neural_networks\\circuit_qnn.py\u001b[0m in \u001b[0;36m_probability_gradients\u001b[1;34m(self, input_data, weights)\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[1;31m# TODO: additional \"bind_parameters\" should not be necessary,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[1;31m#  seems like a bug to be fixed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m             grad = self._sampler.convert(self._grad_circuit, param_values\n\u001b[0m\u001b[0;32m    272\u001b[0m                                          ).bind_parameters(param_values).eval()\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\my-torch\\lib\\site-packages\\qiskit\\opflow\\converters\\circuit_sampler.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self, operator, params)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[0mp_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mParameter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_bindings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         sampled_statefn_dicts = self.sample_circuits(circuit_sfns=circs,\n\u001b[1;32m--> 208\u001b[1;33m                                                      param_bindings=p_b)\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mreplace_circuits_with_dicts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\my-torch\\lib\\site-packages\\qiskit\\opflow\\converters\\circuit_sampler.py\u001b[0m in \u001b[0;36msample_circuits\u001b[1;34m(self, circuit_sfns, param_bindings)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m         results = self.quantum_instance.execute(ready_circs,\n\u001b[1;32m--> 310\u001b[1;33m                                                 had_transpiled=self._transpile_before_bind)\n\u001b[0m\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparam_bindings\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_param_qobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\my-torch\\lib\\site-packages\\qiskit\\utils\\quantum_instance.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, circuits, had_transpiled)\u001b[0m\n\u001b[0;32m    480\u001b[0m                      run_qobj(qobj, self._backend, self._qjob_config,\n\u001b[0;32m    481\u001b[0m                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_noise_config\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m                               self._skip_qobj_validation, self._job_callback)\n\u001b[0m\u001b[0;32m    483\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_time_taken\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime_taken\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\my-torch\\lib\\site-packages\\qiskit\\utils\\run_circuits.py\u001b[0m in \u001b[0;36mrun_qobj\u001b[1;34m(qobj, backend, qjob_config, backend_options, noise_config, skip_qobj_validation, job_callback)\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjobs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m             \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mqjob_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_combine_result_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\my-torch\\lib\\site-packages\\qiskit\\providers\\aer\\aerjob.py\u001b[0m in \u001b[0;36m_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_future\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mJobError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Job not submitted yet!. You have to .submit() first!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\my-torch\\lib\\site-packages\\qiskit\\providers\\aer\\aerjob.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0mconcurrent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCancelledError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mjob\u001b[0m \u001b[0mcancelled\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_future\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mrequires_submit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\my-torch\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\my-torch\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import sys\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "lr_list=[round(((i+1)/10)**2,2) for i in range(20)]\n",
    "ds_list=['0','1a','2a','3c']\n",
    "\n",
    "for dsID in ds_list:\n",
    "# Run the experiment\n",
    "    print('--------dataset',dsID,'is initialized------')\n",
    "    lr_acc=[]\n",
    "    for lr in lr_list:\n",
    "        # Load in the data\n",
    "        data = load_data(dsID)\n",
    "\n",
    "        # Generate the splittings\n",
    "        train_X, train_y, validate_X, validate_y, test_X, test_y = generate_train_validate_test_data(data)\n",
    "\n",
    "        # Make the feature map\n",
    "        feature_map= make_embedding_circuit()\n",
    "\n",
    "        # Make the classifier\n",
    "        ansatz = make_classifer_circuit(circuitID)\n",
    "\n",
    "        # Do the training\n",
    "        model = train_model(feature_map, ansatz, epochs, lr, train_X, train_y)\n",
    "\n",
    "        # Check the validation accuracy.\n",
    "        val_accuracy = check_accuracy(model, validate_X, validate_y)\n",
    "\n",
    "        lr_acc.append([lr,val_accuracy])\n",
    "    np.savetxt(r\"Learning_Rate_Data\\circuit{0}_data{1}.txt\".format(circuitID,dsID),lr_acc,fmt='%.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb500bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__Learning Rate ( 0.01 ) is intialized\n",
      "__Learning Rate ( 0.01 ) is done\n",
      "__Learning Rate ( 0.04 ) is intialized\n",
      "__Learning Rate ( 0.04 ) is done\n",
      "__Learning Rate ( 0.09 ) is intialized\n",
      "__Learning Rate ( 0.09 ) is done\n",
      "__Learning Rate ( 0.16 ) is intialized\n",
      "__Learning Rate ( 0.16 ) is done\n",
      "__Learning Rate ( 0.25 ) is intialized\n",
      "__Learning Rate ( 0.25 ) is done\n",
      "__Learning Rate ( 0.36 ) is intialized\n",
      "__Learning Rate ( 0.36 ) is done\n",
      "__Learning Rate ( 0.49 ) is intialized\n",
      "__Learning Rate ( 0.49 ) is done\n",
      "__Learning Rate ( 0.64 ) is intialized\n",
      "__Learning Rate ( 0.64 ) is done\n",
      "__Learning Rate ( 0.81 ) is intialized\n",
      "__Learning Rate ( 0.81 ) is done\n",
      "__Learning Rate ( 1.0 ) is intialized\n",
      "__Learning Rate ( 1.0 ) is done\n",
      "__Learning Rate ( 1.21 ) is intialized\n",
      "__Learning Rate ( 1.21 ) is done\n",
      "__Learning Rate ( 1.44 ) is intialized\n",
      "__Learning Rate ( 1.44 ) is done\n",
      "__Learning Rate ( 1.69 ) is intialized\n",
      "__Learning Rate ( 1.69 ) is done\n",
      "__Learning Rate ( 1.96 ) is intialized\n",
      "__Learning Rate ( 1.96 ) is done\n",
      "__Learning Rate ( 2.25 ) is intialized\n",
      "__Learning Rate ( 2.25 ) is done\n",
      "__Learning Rate ( 2.56 ) is intialized\n",
      "__Learning Rate ( 2.56 ) is done\n",
      "__Learning Rate ( 2.89 ) is intialized\n",
      "__Learning Rate ( 2.89 ) is done\n",
      "__Learning Rate ( 3.24 ) is intialized\n",
      "__Learning Rate ( 3.24 ) is done\n",
      "__Learning Rate ( 3.61 ) is intialized\n",
      "__Learning Rate ( 3.61 ) is done\n",
      "__Learning Rate ( 4.0 ) is intialized\n",
      "__Learning Rate ( 4.0 ) is done\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import sys\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "lr_list=[round(((i+1)/10)**2,2) for i in range(20)]\n",
    "\n",
    "\n",
    "\n",
    "# Run the experiment\n",
    "\n",
    "lr_acc=[]\n",
    "for lr in lr_list:\n",
    "    # Load in the data\n",
    "    data = load_data('0')\n",
    "\n",
    "    # Generate the splittings\n",
    "    train_X, train_y, validate_X, validate_y, test_X, test_y = generate_train_validate_test_data(data)\n",
    "\n",
    "    # Make the feature map\n",
    "    feature_map= make_embedding_circuit()\n",
    "\n",
    "    # Make the classifier\n",
    "    ansatz = make_classifer_circuit(circuitID)\n",
    "\n",
    "    # Do the training\n",
    "    model = train_model(feature_map, ansatz, epochs, lr, train_X, train_y)\n",
    "\n",
    "    # Check the validation accuracy.\n",
    "    val_accuracy = check_accuracy(model, validate_X, validate_y)\n",
    "\n",
    "    lr_acc.append([lr,val_accuracy])\n",
    "np.savetxt(r\"Learning_Rate_Data\\circuit{0}_data{1}.txt\".format(circuitID,dsID),lr_acc,fmt='%.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aa2e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
