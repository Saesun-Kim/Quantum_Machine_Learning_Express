{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qiskit-terra': '0.17.1', 'qiskit-aer': '0.8.1', 'qiskit-ignis': '0.6.0', 'qiskit-ibmq-provider': '0.12.2', 'qiskit-aqua': '0.9.1', 'qiskit': '0.25.1', 'qiskit-nature': None, 'qiskit-finance': None, 'qiskit-optimization': None, 'qiskit-machine-learning': None}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import qiskit\n",
    "qiskit.__qiskit_version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, CrossEntropyLoss, MSELoss\n",
    "from torch.optim import LBFGS, SGD,Adam \n",
    "\n",
    "from qiskit  import Aer, QuantumCircuit\n",
    "from qiskit.utils import QuantumInstance\n",
    "from qiskit.opflow import AerPauliExpectation\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_machine_learning.neural_networks import CircuitQNN, TwoLayerQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "qi = QuantumInstance(Aer.get_backend('statevector_simulator'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Test 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import pi\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.nn import (Module, Conv2d, Linear, Dropout2d, NLLLoss,\n",
    "                     MaxPool2d, Flatten, Sequential, ReLU)\n",
    "\n",
    "data0Path = r'../dataset/data0test.txt'\n",
    "data0Label = r'../dataset/data0testlabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data0Path)\n",
    "dataLabels = np.loadtxt(data0Label)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.355628967285156\n",
      "34.73762512207031\n",
      "28.43988800048828\n",
      "26.591997146606445\n",
      "26.20227813720703\n",
      "26.127466201782227\n",
      "26.09093475341797\n",
      "26.20258331298828\n",
      "25.805492401123047\n",
      "25.489187240600586\n",
      "44.570762634277344\n",
      "52.83230972290039\n",
      "53.89324188232422\n",
      "36.02682113647461\n",
      "62.769012451171875\n",
      "53.54864501953125\n",
      "41.90972900390625\n",
      "38.811431884765625\n",
      "31.93553352355957\n",
      "63.6278190612793\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=60)\n",
    "\n",
    "X = [data[j][0] for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "\n",
    "num_inputs=2;\n",
    "\n",
    "feature_map = QuantumCircuit(2, name='Embed')\n",
    "feature_map.rx(pi*Parameter('x[0]'),0)\n",
    "feature_map.rx(pi*Parameter('x[1]'),1)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "\n",
    "param_y=[];\n",
    "for i in range(5):\n",
    "    param_y.append((Parameter('Î¸'+str(i))))\n",
    "ansatz = QuantumCircuit(2, name='PQC')\n",
    "for i in range(2):\n",
    "    ansatz.rx(param_y[i],i)\n",
    "for i in range(2):\n",
    "    ansatz.rz(param_y[i+2],i)\n",
    "ansatz.crx(param_y[4],1,0)\n",
    "\n",
    "\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: '{:b}'.format(x).count('1') % 2\n",
    "output_shape = 2  # parity = 0, 1\n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters())\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9833333333333333\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.contour.QuadContourSet at 0x167820880d0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=10)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.29439926147461\n"
     ]
    }
   ],
   "source": [
    "data1aPath = r'../dataset/data1a.txt'\n",
    "data1aLabel = r'../dataset/data1alabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1aPath)\n",
    "dataLabels = np.loadtxt(data1aLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=60)\n",
    "\n",
    "X = [data[j][0] for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "\n",
    "num_inputs=2;\n",
    "\n",
    "feature_map = QuantumCircuit(2, name='Embed')\n",
    "feature_map.rx(pi*Parameter('x[0]'),0)\n",
    "feature_map.rx(pi*Parameter('x[1]'),1)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(5):\n",
    "    param_y.append((Parameter('Î¸'+str(i))))\n",
    "ansatz = QuantumCircuit(2, name='PQC')\n",
    "for i in range(2):\n",
    "    ansatz.rx(param_y[i],i)\n",
    "for i in range(2):\n",
    "    ansatz.rz(param_y[i+2],i)\n",
    "ansatz.crx(param_y[4],1,0)\n",
    "\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: '{:b}'.format(x).count('1') % 2\n",
    "output_shape = 2  # parity = 0, 1\n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters())\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=5)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1bPath = r'../dataset/data1b.txt'\n",
    "data1bLabel = r'../dataset/data1blabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1bPath)\n",
    "dataLabels = np.loadtxt(data1bLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=60)\n",
    "\n",
    "X = [data[j][0] for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "\n",
    "num_inputs=2;\n",
    "\n",
    "feature_map = QuantumCircuit(2, name='Embed')\n",
    "feature_map.rx(pi*Parameter('x[0]'),0)\n",
    "feature_map.rx(pi*Parameter('x[1]'),1)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(5):\n",
    "    param_y.append((Parameter('Î¸'+str(i))))\n",
    "ansatz = QuantumCircuit(2, name='PQC')\n",
    "for i in range(2):\n",
    "    ansatz.rx(param_y[i],i)\n",
    "for i in range(2):\n",
    "    ansatz.rz(param_y[i+2],i)\n",
    "ansatz.crx(param_y[4],1,0)\n",
    "\n",
    "\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: '{:b}'.format(x).count('1') % 2\n",
    "output_shape = 2  # parity = 0, 1\n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters())\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=5)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1aPath = r'../dataset/data1c.txt'\n",
    "data1aLabel = r'../dataset/data1clabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1aPath)\n",
    "dataLabels = np.loadtxt(data1aLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=60)\n",
    "\n",
    "X = [data[j][0] for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "\n",
    "num_inputs=2;\n",
    "\n",
    "feature_map = QuantumCircuit(2, name='Embed')\n",
    "feature_map.rx(pi*Parameter('x[0]'),0)\n",
    "feature_map.rx(pi*Parameter('x[1]'),1)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(5):\n",
    "    param_y.append((Parameter('Î¸'+str(i))))\n",
    "ansatz = QuantumCircuit(2, name='PQC')\n",
    "for i in range(2):\n",
    "    ansatz.rx(param_y[i],i)\n",
    "for i in range(2):\n",
    "    ansatz.rz(param_y[i+2],i)\n",
    "ansatz.crx(param_y[4],1,0)\n",
    "\n",
    "\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: '{:b}'.format(x).count('1') % 2\n",
    "output_shape = 2  # parity = 0, 1\n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters())\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=5)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1aPath = r'../dataset/data2a.txt'\n",
    "data1aLabel = r'../dataset/data2alabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1aPath)\n",
    "dataLabels = np.loadtxt(data1aLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=60)\n",
    "\n",
    "X = [data[j][0] for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "\n",
    "num_inputs=2;\n",
    "\n",
    "feature_map = QuantumCircuit(2, name='Embed')\n",
    "feature_map.rx(pi*Parameter('x[0]'),0)\n",
    "feature_map.rx(pi*Parameter('x[1]'),1)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(5):\n",
    "    param_y.append((Parameter('Î¸'+str(i))))\n",
    "ansatz = QuantumCircuit(2, name='PQC')\n",
    "for i in range(2):\n",
    "    ansatz.rx(param_y[i],i)\n",
    "for i in range(2):\n",
    "    ansatz.rz(param_y[i+2],i)\n",
    "ansatz.crx(param_y[4],1,0)\n",
    "\n",
    "\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: '{:b}'.format(x).count('1') % 2\n",
    "output_shape = 2  # parity = 0, 1\n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters())\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=5)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1aPath = r'../dataset/data2b.txt'\n",
    "data1aLabel = r'../dataset/data2blabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1aPath)\n",
    "dataLabels = np.loadtxt(data1aLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=60)\n",
    "\n",
    "X = [data[j][0] for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "\n",
    "num_inputs=2;\n",
    "\n",
    "feature_map = QuantumCircuit(2, name='Embed')\n",
    "feature_map.rx(pi*Parameter('x[0]'),0)\n",
    "feature_map.rx(pi*Parameter('x[1]'),1)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(5):\n",
    "    param_y.append((Parameter('Î¸'+str(i))))\n",
    "ansatz = QuantumCircuit(2, name='PQC')\n",
    "for i in range(2):\n",
    "    ansatz.rx(param_y[i],i)\n",
    "for i in range(2):\n",
    "    ansatz.rz(param_y[i+2],i)\n",
    "ansatz.crx(param_y[4],1,0)\n",
    "\n",
    "\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: '{:b}'.format(x).count('1') % 2\n",
    "output_shape = 2  # parity = 0, 1\n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters())\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=5)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1aPath = r'../dataset/data2c.txt'\n",
    "data1aLabel = r'../dataset/data2clabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1aPath)\n",
    "dataLabels = np.loadtxt(data1aLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=60)\n",
    "\n",
    "X = [data[j][0] for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "\n",
    "num_inputs=2;\n",
    "\n",
    "feature_map = QuantumCircuit(2, name='Embed')\n",
    "feature_map.rx(pi*Parameter('x[0]'),0)\n",
    "feature_map.rx(pi*Parameter('x[1]'),1)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(5):\n",
    "    param_y.append((Parameter('Î¸'+str(i))))\n",
    "ansatz = QuantumCircuit(2, name='PQC')\n",
    "for i in range(2):\n",
    "    ansatz.rx(param_y[i],i)\n",
    "for i in range(2):\n",
    "    ansatz.rz(param_y[i+2],i)\n",
    "ansatz.crx(param_y[4],1,0)\n",
    "\n",
    "\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: '{:b}'.format(x).count('1') % 2\n",
    "output_shape = 2  # parity = 0, 1\n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters())\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=5)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1aPath = r'../dataset/data3a.txt'\n",
    "data1aLabel = r'../dataset/data3alabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1aPath)\n",
    "dataLabels = np.loadtxt(data1aLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=60)\n",
    "\n",
    "X = [data[j][0] for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "\n",
    "num_inputs=2;\n",
    "\n",
    "feature_map = QuantumCircuit(2, name='Embed')\n",
    "feature_map.rx(pi*Parameter('x[0]'),0)\n",
    "feature_map.rx(pi*Parameter('x[1]'),1)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "\n",
    "param_y=[];\n",
    "for i in range(5):\n",
    "    param_y.append((Parameter('Î¸'+str(i))))\n",
    "ansatz = QuantumCircuit(2, name='PQC')\n",
    "for i in range(2):\n",
    "    ansatz.rx(param_y[i],i)\n",
    "for i in range(2):\n",
    "    ansatz.rz(param_y[i+2],i)\n",
    "ansatz.crx(param_y[4],1,0)\n",
    "\n",
    "\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: '{:b}'.format(x).count('1') % 2\n",
    "output_shape = 2  # parity = 0, 1\n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters())\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=5)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1aPath = r'../dataset/data3b.txt'\n",
    "data1aLabel = r'../dataset/data3blabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1aPath)\n",
    "dataLabels = np.loadtxt(data1aLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=60)\n",
    "\n",
    "X = [data[j][0] for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "\n",
    "num_inputs=2;\n",
    "\n",
    "feature_map = QuantumCircuit(2, name='Embed')\n",
    "feature_map.rx(pi*Parameter('x[0]'),0)\n",
    "feature_map.rx(pi*Parameter('x[1]'),1)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(5):\n",
    "    param_y.append((Parameter('Î¸'+str(i))))\n",
    "ansatz = QuantumCircuit(2, name='PQC')\n",
    "for i in range(2):\n",
    "    ansatz.rx(param_y[i],i)\n",
    "for i in range(2):\n",
    "    ansatz.rz(param_y[i+2],i)\n",
    "ansatz.crx(param_y[4],1,0)\n",
    "\n",
    "\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: '{:b}'.format(x).count('1') % 2\n",
    "output_shape = 2  # parity = 0, 1\n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters())\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=5)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 3c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1aPath = r'../dataset/data3c.txt'\n",
    "data1aLabel = r'../dataset/data3clabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1aPath)\n",
    "dataLabels = np.loadtxt(data1aLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=60)\n",
    "\n",
    "X = [data[j][0] for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "\n",
    "num_inputs=2;\n",
    "\n",
    "feature_map = QuantumCircuit(2, name='Embed')\n",
    "feature_map.rx(pi*Parameter('x[0]'),0)\n",
    "feature_map.rx(pi*Parameter('x[1]'),1)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(5):\n",
    "    param_y.append((Parameter('Î¸'+str(i))))\n",
    "ansatz = QuantumCircuit(2, name='PQC')\n",
    "for i in range(2):\n",
    "    ansatz.rx(param_y[i],i)\n",
    "for i in range(2):\n",
    "    ansatz.rz(param_y[i+2],i)\n",
    "ansatz.crx(param_y[4],1,0)\n",
    "\n",
    "\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: '{:b}'.format(x).count('1') % 2\n",
    "output_shape = 2  # parity = 0, 1\n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters())\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=5)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
