{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qiskit-terra': '0.17.1', 'qiskit-aer': '0.8.1', 'qiskit-ignis': '0.6.0', 'qiskit-ibmq-provider': '0.12.2', 'qiskit-aqua': '0.9.1', 'qiskit': '0.25.1', 'qiskit-nature': None, 'qiskit-finance': None, 'qiskit-optimization': None, 'qiskit-machine-learning': None}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import qiskit\n",
    "qiskit.__qiskit_version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, CrossEntropyLoss, MSELoss\n",
    "from torch.optim import LBFGS, SGD,Adam \n",
    "\n",
    "from qiskit  import Aer, QuantumCircuit\n",
    "from qiskit.utils import QuantumInstance\n",
    "from qiskit.opflow import AerPauliExpectation\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_machine_learning.neural_networks import CircuitQNN, TwoLayerQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.nn import (Module, Conv2d, Linear, Dropout2d, NLLLoss,\n",
    "                     MaxPool2d, Flatten, Sequential, ReLU)\n",
    "\n",
    "qi = QuantumInstance(Aer.get_backend('statevector_simulator'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Test 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import pi\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.nn import (Module, Conv2d, Linear, Dropout2d, NLLLoss,\n",
    "                     MaxPool2d, Flatten, Sequential, ReLU)\n",
    "\n",
    "data0Path = r'../../dataset/data3c.txt'\n",
    "data0Label = r'../../dataset/data3clabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data0Path)\n",
    "dataLabels = np.loadtxt(data0Label)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data1 = list(zip(dataCoords, 2*dataLabels-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.core.common import flatten\n",
    "import torch\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data1), size=100)\n",
    "\n",
    "X= [np.array(list(flatten([data1[j][0],data1[j][0]]))) for j in data_ixs]\n",
    "y = [data1[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "num_inputs=4;\n",
    "apram=0.1*pi\n",
    "feature_map = QuantumCircuit(4, name='Embed')\n",
    "feature_map.rx(apram*Parameter('x[0]'),0)\n",
    "feature_map.rx(apram*Parameter('x[1]'),1)\n",
    "feature_map.rx(apram*Parameter('x[2]'),2)\n",
    "feature_map.rx(apram*Parameter('x[3]'),3)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.ry(pi/4,2)\n",
    "feature_map.ry(pi/4,3)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "feature_map.rz(pi/4,2)\n",
    "feature_map.rz(pi/4,3)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(12):\n",
    "    param_y.append((Parameter('Î¸'+str(i))))\n",
    "ansatz = QuantumCircuit(4, name='PQC')\n",
    "for i in range(4):\n",
    "    ansatz.ry(param_y[i],i)\n",
    "for i in range(4):\n",
    "    ansatz.rz(param_y[i+4],i)\n",
    "ansatz.cx(0,1)\n",
    "ansatz.cx(2,3)\n",
    "ansatz.ry(param_y[8],1)\n",
    "ansatz.ry(param_y[9],2)\n",
    "ansatz.rz(param_y[10],1)\n",
    "ansatz.rz(param_y[11],2)\n",
    "ansatz.cx(1,2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: firsttwo(binary(x)).count('1') % 2\n",
    "output_shape = 2  \n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.3*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary(x):\n",
    "    return ('0'*(4-len('{:b}'.format(x) ))+'{:b}'.format(x))\n",
    "def firsttwo(x):\n",
    "    return x[:2]\n",
    "parity = lambda x: firsttwo(binary(x)).count('1') % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saesun Kim\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# define optimizer and loss function\n",
    "optimizer = LBFGS(model2.parameters())\n",
    "f_loss = MSELoss(reduction='sum')\n",
    "\n",
    "# start training\n",
    "model2.train()   # set model to training mode\n",
    "\n",
    "# define objective function\n",
    "def closure():\n",
    "    optimizer.zero_grad()        # initialize gradient\n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        targets=Tensor([y_target]).long()\n",
    "        targets = targets.to(torch.float32)\n",
    "        loss += f_loss(output, targets) \n",
    "    loss.backward()                              # backward pass\n",
    "    print(loss.item())                           # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer\n",
    "optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=20)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j],X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.3*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "# define optimizer and loss function\n",
    "optimizer = optim.SGD(model2.parameters(),lr=1)\n",
    "f_loss = MSELoss(reduction='sum')\n",
    "\n",
    "# start training\n",
    "model2.train()   # set model to training mode\n",
    "epochs = 50     # set number of epochs\n",
    "\n",
    "# define objective function\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()        # initialize gradient\n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        targets=Tensor([y_target]).long()\n",
    "        targets = targets.to(torch.float32)\n",
    "        loss += f_loss(output, targets) \n",
    "    loss.backward()                              # backward pass\n",
    "    print(loss.item())                           # print loss\n",
    "\n",
    "    # run optimizer\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=20)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j],X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.3*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define optimizer and loss function\n",
    "optimizer = optim.Adam(model2.parameters(), lr=0.1)\n",
    "f_loss = MSELoss(reduction='sum')\n",
    "\n",
    "# start training\n",
    "model2.train()   # set model to training mode\n",
    "epochs = 100     # set number of epochs\n",
    "\n",
    "# define objective function\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()        # initialize gradient\n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        targets=Tensor([y_target]).long()\n",
    "        targets = targets.to(torch.float32)\n",
    "        loss += f_loss(output, targets) \n",
    "    loss.backward()                              # backward pass\n",
    "    print(loss.item())                           # print loss\n",
    "\n",
    "    # run optimizer\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=20)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j],X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
