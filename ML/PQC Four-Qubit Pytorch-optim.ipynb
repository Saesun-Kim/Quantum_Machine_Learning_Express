{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qiskit-terra': '0.17.1', 'qiskit-aer': '0.8.1', 'qiskit-ignis': '0.6.0', 'qiskit-ibmq-provider': '0.12.2', 'qiskit-aqua': '0.9.1', 'qiskit': '0.25.1', 'qiskit-nature': None, 'qiskit-finance': None, 'qiskit-optimization': None, 'qiskit-machine-learning': None}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import qiskit\n",
    "qiskit.__qiskit_version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, CrossEntropyLoss, MSELoss\n",
    "from torch.optim import LBFGS, SGD,Adam \n",
    "\n",
    "from qiskit  import Aer, QuantumCircuit\n",
    "from qiskit.utils import QuantumInstance\n",
    "from qiskit.opflow import AerPauliExpectation\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_machine_learning.neural_networks import CircuitQNN, TwoLayerQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "qi = QuantumInstance(Aer.get_backend('statevector_simulator'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Test 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import pi\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.nn import (Module, Conv2d, Linear, Dropout2d, NLLLoss,\n",
    "                     MaxPool2d, Flatten, Sequential, ReLU)\n",
    "\n",
    "data0Path = r'../dataset/data3c.txt'\n",
    "data0Label = r'../dataset/data3clabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data0Path)\n",
    "dataLabels = np.loadtxt(data0Label)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.core.common import flatten\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=100)\n",
    "\n",
    "X= [np.array(list(flatten([data[j][0],data[j][0]]))) for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "num_inputs=4;\n",
    "\n",
    "feature_map = QuantumCircuit(4, name='Embed')\n",
    "feature_map.rx(Parameter('x[0]'),0)\n",
    "feature_map.rx(Parameter('x[1]'),1)\n",
    "feature_map.rx(Parameter('x[2]'),2)\n",
    "feature_map.rx(Parameter('x[3]'),3)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.ry(pi/4,2)\n",
    "feature_map.ry(pi/4,3)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "feature_map.rz(pi/4,2)\n",
    "feature_map.rz(pi/4,3)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(12):\n",
    "    param_y.append((Parameter('Î¸'+str(i))))\n",
    "ansatz = QuantumCircuit(4, name='PQC')\n",
    "for i in range(4):\n",
    "    ansatz.ry(param_y[i],i)\n",
    "for i in range(4):\n",
    "    ansatz.rz(param_y[i+4],i)\n",
    "ansatz.cx(0,1)\n",
    "ansatz.cx(2,3)\n",
    "ansatz.ry(param_y[8],1)\n",
    "ansatz.ry(param_y[9],2)\n",
    "ansatz.rz(param_y[10],1)\n",
    "ansatz.rz(param_y[11],2)\n",
    "ansatz.cx(1,2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: firsttwo(binary(x)).count('1') % 2\n",
    "output_shape = 2  \n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters(),lr=0.01,tolerance_grad=1e-09, tolerance_change=1e-11)\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary(x):\n",
    "    return ('0'*(4-len('{:b}'.format(x) ))+'{:b}'.format(x))\n",
    "def firsttwo(x):\n",
    "    return x[:2]\n",
    "parity = lambda x: firsttwo(binary(x)).count('1') % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=10)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1aPath = r'../dataset/data1a.txt'\n",
    "data1aLabel = r'../dataset/data1alabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1aPath)\n",
    "dataLabels = np.loadtxt(data1aLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=100)\n",
    "\n",
    "X= [np.array(list(flatten([data[j][0],data[j][0]]))) for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "num_inputs=4;\n",
    "\n",
    "feature_map = QuantumCircuit(4, name='Embed')\n",
    "feature_map.rx(Parameter('x[0]'),0)\n",
    "feature_map.rx(Parameter('x[1]'),1)\n",
    "feature_map.rx(Parameter('x[2]'),2)\n",
    "feature_map.rx(Parameter('x[3]'),3)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.ry(pi/4,2)\n",
    "feature_map.ry(pi/4,3)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "feature_map.rz(pi/4,2)\n",
    "feature_map.rz(pi/4,3)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(12):\n",
    "    param_y.append((Parameter('Î¸'+str(i))))\n",
    "ansatz = QuantumCircuit(4, name='PQC')\n",
    "for i in range(4):\n",
    "    ansatz.ry(param_y[i],i)\n",
    "for i in range(4):\n",
    "    ansatz.rz(param_y[i+4],i)\n",
    "ansatz.cx(0,1)\n",
    "ansatz.cx(2,3)\n",
    "ansatz.ry(param_y[8],1)\n",
    "ansatz.ry(param_y[9],2)\n",
    "ansatz.rz(param_y[10],1)\n",
    "ansatz.rz(param_y[11],2)\n",
    "ansatz.cx(1,2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: firsttwo(binary(x)).count('1') % 2\n",
    "output_shape = 2  \n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters(),lr=0.01,tolerance_grad=1e-09, tolerance_change=1e-11)\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=5)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1bPath = r'../dataset/data1b.txt'\n",
    "data1bLabel = r'../dataset/data1blabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1bPath)\n",
    "dataLabels = np.loadtxt(data1bLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=100)\n",
    "\n",
    "X= [np.array(list(flatten([data[j][0],data[j][0]]))) for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "num_inputs=4;\n",
    "\n",
    "feature_map = QuantumCircuit(4, name='Embed')\n",
    "feature_map.rx(Parameter('x[0]'),0)\n",
    "feature_map.rx(Parameter('x[1]'),1)\n",
    "feature_map.rx(Parameter('x[2]'),2)\n",
    "feature_map.rx(Parameter('x[3]'),3)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.ry(pi/4,2)\n",
    "feature_map.ry(pi/4,3)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "feature_map.rz(pi/4,2)\n",
    "feature_map.rz(pi/4,3)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(12):\n",
    "    param_y.append((Parameter('Î¸'+str(i))))\n",
    "ansatz = QuantumCircuit(4, name='PQC')\n",
    "for i in range(4):\n",
    "    ansatz.ry(param_y[i],i)\n",
    "for i in range(4):\n",
    "    ansatz.rz(param_y[i+4],i)\n",
    "ansatz.cx(0,1)\n",
    "ansatz.cx(2,3)\n",
    "ansatz.ry(param_y[8],1)\n",
    "ansatz.ry(param_y[9],2)\n",
    "ansatz.rz(param_y[10],1)\n",
    "ansatz.rz(param_y[11],2)\n",
    "ansatz.cx(1,2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: firsttwo(binary(x)).count('1') % 2\n",
    "output_shape = 2  \n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters(),lr=0.01,tolerance_grad=1e-09, tolerance_change=1e-11)\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=5)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.63034057617188\n"
     ]
    }
   ],
   "source": [
    "data1aPath = r'../dataset/data1c.txt'\n",
    "data1aLabel = r'../dataset/data1clabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1aPath)\n",
    "dataLabels = np.loadtxt(data1aLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=100)\n",
    "\n",
    "X = [data[j][0] for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "\n",
    "num_inputs=2;\n",
    "\n",
    "feature_map = QuantumCircuit(2, name='Embed')\n",
    "feature_map.rx(pi*Parameter('x[0]'),0)\n",
    "feature_map.rx(pi*Parameter('x[1]'),1)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(4):\n",
    "    param_y.append((Parameter('Î¸'+str(i))))\n",
    "ansatz = QuantumCircuit(2, name='PQC')\n",
    "for i in range(2):\n",
    "    ansatz.rx(param_y[i],i)\n",
    "for i in range(2):\n",
    "    ansatz.rz(param_y[i+2],i)\n",
    "    \n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: '{:b}'.format(x).count('1') % 2\n",
    "output_shape = 2  # parity = 0, 1\n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters())\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=5)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1aPath = r'../dataset/data2a.txt'\n",
    "data1aLabel = r'../dataset/data2alabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1aPath)\n",
    "dataLabels = np.loadtxt(data1aLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=100)\n",
    "\n",
    "X = [data[j][0] for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "\n",
    "num_inputs=2;\n",
    "\n",
    "feature_map = QuantumCircuit(2, name='Embed')\n",
    "feature_map.rx(pi*Parameter('x[0]'),0)\n",
    "feature_map.rx(pi*Parameter('x[1]'),1)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(4):\n",
    "    param_y.append((Parameter('Î¸'+str(i))))\n",
    "ansatz = QuantumCircuit(2, name='PQC')\n",
    "for i in range(2):\n",
    "    ansatz.rx(param_y[i],i)\n",
    "for i in range(2):\n",
    "    ansatz.rz(param_y[i+2],i)\n",
    "    \n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: '{:b}'.format(x).count('1') % 2\n",
    "output_shape = 2  # parity = 0, 1\n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters())\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=5)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1aPath = r'../dataset/data2b.txt'\n",
    "data1aLabel = r'../dataset/data2blabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1aPath)\n",
    "dataLabels = np.loadtxt(data1aLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=100)\n",
    "\n",
    "X = [data[j][0] for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "\n",
    "num_inputs=2;\n",
    "\n",
    "feature_map = QuantumCircuit(2, name='Embed')\n",
    "feature_map.rx(pi*Parameter('x[0]'),0)\n",
    "feature_map.rx(pi*Parameter('x[1]'),1)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(4):\n",
    "    param_y.append((Parameter('Î¸'+str(i))))\n",
    "ansatz = QuantumCircuit(2, name='PQC')\n",
    "for i in range(2):\n",
    "    ansatz.rx(param_y[i],i)\n",
    "for i in range(2):\n",
    "    ansatz.rz(param_y[i+2],i)\n",
    "    \n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: '{:b}'.format(x).count('1') % 2\n",
    "output_shape = 2  # parity = 0, 1\n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters())\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=5)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1aPath = r'../dataset/data2c.txt'\n",
    "data1aLabel = r'../dataset/data2clabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1aPath)\n",
    "dataLabels = np.loadtxt(data1aLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=100)\n",
    "\n",
    "X = [data[j][0] for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "\n",
    "num_inputs=2;\n",
    "\n",
    "feature_map = QuantumCircuit(2, name='Embed')\n",
    "feature_map.rx(pi*Parameter('x[0]'),0)\n",
    "feature_map.rx(pi*Parameter('x[1]'),1)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(4):\n",
    "    param_y.append((Parameter('Î¸'+str(i))))\n",
    "ansatz = QuantumCircuit(2, name='PQC')\n",
    "for i in range(2):\n",
    "    ansatz.rx(param_y[i],i)\n",
    "for i in range(2):\n",
    "    ansatz.rz(param_y[i+2],i)\n",
    "    \n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: '{:b}'.format(x).count('1') % 2\n",
    "output_shape = 2  # parity = 0, 1\n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters())\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=5)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1aPath = r'../dataset/data3a.txt'\n",
    "data1aLabel = r'../dataset/data3alabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1aPath)\n",
    "dataLabels = np.loadtxt(data1aLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=100)\n",
    "\n",
    "X = [data[j][0] for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "\n",
    "num_inputs=2;\n",
    "\n",
    "feature_map = QuantumCircuit(2, name='Embed')\n",
    "feature_map.rx(pi*Parameter('x[0]'),0)\n",
    "feature_map.rx(pi*Parameter('x[1]'),1)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(4):\n",
    "    param_y.append((Parameter('Î¸'+str(i))))\n",
    "ansatz = QuantumCircuit(2, name='PQC')\n",
    "for i in range(2):\n",
    "    ansatz.rx(param_y[i],i)\n",
    "for i in range(2):\n",
    "    ansatz.rz(param_y[i+2],i)\n",
    "    \n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: '{:b}'.format(x).count('1') % 2\n",
    "output_shape = 2  # parity = 0, 1\n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters())\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=5)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1aPath = r'../dataset/data3b.txt'\n",
    "data1aLabel = r'../dataset/data3blabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1aPath)\n",
    "dataLabels = np.loadtxt(data1aLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=100)\n",
    "\n",
    "X = [data[j][0] for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "\n",
    "num_inputs=2;\n",
    "\n",
    "feature_map = QuantumCircuit(2, name='Embed')\n",
    "feature_map.rx(pi*Parameter('x[0]'),0)\n",
    "feature_map.rx(pi*Parameter('x[1]'),1)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(4):\n",
    "    param_y.append((Parameter('Î¸'+str(i))))\n",
    "ansatz = QuantumCircuit(2, name='PQC')\n",
    "for i in range(2):\n",
    "    ansatz.rx(param_y[i],i)\n",
    "for i in range(2):\n",
    "    ansatz.rz(param_y[i+2],i)\n",
    "    \n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: '{:b}'.format(x).count('1') % 2\n",
    "output_shape = 2  # parity = 0, 1\n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters())\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=5)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 3c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1aPath = r'../dataset/data3c.txt'\n",
    "data1aLabel = r'../dataset/data3clabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1aPath)\n",
    "dataLabels = np.loadtxt(data1aLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=100)\n",
    "\n",
    "X = [data[j][0] for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "\n",
    "num_inputs=2;\n",
    "\n",
    "feature_map = QuantumCircuit(2, name='Embed')\n",
    "feature_map.rx(pi*Parameter('x[0]'),0)\n",
    "feature_map.rx(pi*Parameter('x[1]'),1)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(4):\n",
    "    param_y.append((Parameter('Î¸'+str(i))))\n",
    "ansatz = QuantumCircuit(2, name='PQC')\n",
    "for i in range(2):\n",
    "    ansatz.rx(param_y[i],i)\n",
    "for i in range(2):\n",
    "    ansatz.rz(param_y[i+2],i)\n",
    "    \n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: '{:b}'.format(x).count('1') % 2\n",
    "output_shape = 2  # parity = 0, 1\n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters())\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=5)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
